{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "Lhix2C2f0Zen",
    "outputId": "3115853f-43fa-49d8-a913-7b295f10fed4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b3bf3c2d-26ed-4df2-8a1c-7e511dfdbf94\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b3bf3c2d-26ed-4df2-8a1c-7e511dfdbf94\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bam_resnet50.pth to bam_resnet50.pth\n",
      "Saving cbam_resnet50.pth to cbam_resnet50.pth\n",
      "Saving densenet121.pth to densenet121.pth\n",
      "Saving efficientnet_b2.pth to efficientnet_b2.pth\n",
      "Saving googlenet.pth to googlenet.pth\n",
      "Saving inception_v3.pth to inception_v3.pth\n",
      "Saving resnet34.pth to resnet34.pth\n",
      "Saving resnet152.pth to resnet152.pth\n",
      "Saving simplecnn.pth to simplecnn.pth\n",
      "Saving vgg19.pth to vgg19.pth\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "Oe1g8LSvhd4N",
    "outputId": "affc38bc-4147-4759-d76b-8efc4ad1b29d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2dffd292-ac8a-47ce-841c-3b472b79ba16\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2dffd292-ac8a-47ce-841c-3b472b79ba16\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "!mkdir ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es2zOA66hhKl",
    "outputId": "1434a550-d2a1-4cbe-bdd3-a4d07ef563e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
      "License(s): DbCL-1.0\n",
      "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  fer2013.zip\n",
      "replace ./data/test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: ./data/test/angry/PrivateTest_10131363.jpg  \n",
      "replace ./data/test/angry/PrivateTest_10304478.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: ./data/test/angry/PrivateTest_10304478.jpg  \n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
      "error:  invalid response [a]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
      "error:  invalid response [{ENTER}]\n",
      "replace ./data/test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d msambare/fer2013\n",
    "!unzip fer2013.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1rS0sg6hwSX",
    "outputId": "970c6fe0-cc64-4fe6-f3fe-14f4836e228f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 7\n",
      "\n",
      "Loading models...\n",
      "\n",
      "==================================================\n",
      "Individual Model Accuracies:\n",
      "==================================================\n",
      "ResNet34            :  66.49%\n",
      "ResNet152           :  65.13%\n",
      "DenseNet121         :  68.22%\n",
      "EfficientNet-B2     :  69.91%\n",
      "GoogLeNet           :  54.39%\n",
      "InceptionV3         :  34.69%\n",
      "VGG19               :  66.62%\n",
      "SimpleCNN           :   2.28%\n",
      "BAM-ResNet50        :  65.87%\n",
      "CBAM-ResNet50       :  63.43%\n",
      "\n",
      "==================================================\n",
      "Ensemble Accuracy: 72.19%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Define Transforms\n",
    "# ----------------------------\n",
    "transform_common = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_inception = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((299, 299)),  # InceptionV3 needs 299x299\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# SimpleCNN expects grayscale (1 channel) input\n",
    "transform_grayscale = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Keep as 1 channel\n",
    "    transforms.Resize((48, 48)),  # SimpleCNN was trained on 48x48\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Single channel normalization\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define Custom Models\n",
    "# ----------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=(2,3), keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=2, keepdim=True)\n",
    "        max_out, _ = torch.max(max_out, dim=3, keepdim=True)\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(avg_out)))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(max_out)))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class BAM(nn.Module):\n",
    "    def __init__(self, in_planes):\n",
    "        super(BAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = self.ca(x) * x\n",
    "        x_out = self.sa(x_out) * x_out\n",
    "        return x_out\n",
    "\n",
    "class BAM_ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(BAM_ResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        self.bam1 = BAM(256)\n",
    "        self.bam2 = BAM(512)\n",
    "        self.bam3 = BAM(1024)\n",
    "        self.bam4 = BAM(2048)\n",
    "        self.resnet.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.bam1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.bam2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.bam3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.bam4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "        return x\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, ratio=16, kernel_size=7):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.ca = ChannelAttention(channels, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "class CBAM_ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(CBAM_ResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        self.cbam1 = CBAMBlock(256)\n",
    "        self.cbam2 = CBAMBlock(512)\n",
    "        self.cbam3 = CBAMBlock(1024)\n",
    "        self.cbam4 = CBAMBlock(2048)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.cbam1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.cbam2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.cbam3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.cbam4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "        return x\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Model Loaders\n",
    "# ----------------------------\n",
    "def load_resnet34(path, num_classes):\n",
    "    model = models.resnet34(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_resnet152(path, num_classes):\n",
    "    model = models.resnet152(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_densenet121(path, num_classes):\n",
    "    model = models.densenet121(weights=None)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_efficientnet_b2(path, num_classes):\n",
    "    model = timm.create_model(\"efficientnet_b2\", pretrained=False, num_classes=num_classes)\n",
    "    state = torch.load(path, map_location=device)\n",
    "\n",
    "    # Try loading with prefix handling\n",
    "    new_state = {}\n",
    "    for k, v in state.items():\n",
    "        nk = k.replace(\"module.\", \"\").replace(\"model.\", \"\")\n",
    "        new_state[nk] = v\n",
    "\n",
    "    model.load_state_dict(new_state, strict=False)\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_googlenet(path, num_classes):\n",
    "    # Load with aux_logits=True to match training checkpoint structure\n",
    "    model = models.googlenet(weights=None, aux_logits=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    # Modify aux classifiers to match our num_classes\n",
    "    if hasattr(model, 'aux1') and model.aux1 is not None:\n",
    "        model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, num_classes)\n",
    "    if hasattr(model, 'aux2') and model.aux2 is not None:\n",
    "        model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, num_classes)\n",
    "\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "\n",
    "    # Filter out incompatible auxiliary classifier weights (they have 1000 classes from pretrained)\n",
    "    filtered_state = {k: v for k, v in state_dict.items()\n",
    "                     if not (k.startswith('aux1.fc2.') or k.startswith('aux2.fc2.'))}\n",
    "\n",
    "    model.load_state_dict(filtered_state, strict=False)\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_inception_v3(path, num_classes):\n",
    "    # Load with aux_logits=True to match checkpoint structure from training\n",
    "    model = models.inception_v3(weights=None, aux_logits=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    # Modify aux classifier\n",
    "    if model.AuxLogits is not None:\n",
    "        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
    "\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "\n",
    "    # Filter out incompatible auxiliary classifier weights (they have 1000 classes from pretrained)\n",
    "    filtered_state = {k: v for k, v in state_dict.items()\n",
    "                     if not k.startswith('AuxLogits.fc.')}\n",
    "\n",
    "    model.load_state_dict(filtered_state, strict=False)\n",
    "\n",
    "    # Now disable aux_logits for inference\n",
    "    model.aux_logits = False\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_vgg19(path, num_classes):\n",
    "    model = models.vgg19(weights=None)\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_simplecnn(path, num_classes):\n",
    "    model = SimpleCNN(num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_bam_resnet50(path, num_classes):\n",
    "    model = BAM_ResNet50(num_classes=num_classes)\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_cbam_resnet50(path, num_classes):\n",
    "    model = CBAM_ResNet50(num_classes=num_classes)\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    return model.to(device).eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Load Dataset\n",
    "# ----------------------------\n",
    "test_dir = \"./data/test\"\n",
    "\n",
    "# Create separate datasets for different input sizes\n",
    "test_dataset_224 = datasets.ImageFolder(test_dir, transform=transform_common)\n",
    "test_dataset_299 = datasets.ImageFolder(test_dir, transform=transform_inception)\n",
    "test_dataset_gray = datasets.ImageFolder(test_dir, transform=transform_grayscale)\n",
    "\n",
    "test_loader_224 = DataLoader(test_dataset_224, batch_size=32, shuffle=False)\n",
    "test_loader_299 = DataLoader(test_dataset_299, batch_size=32, shuffle=False)\n",
    "test_loader_gray = DataLoader(test_dataset_gray, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(test_dataset_224.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Load Models\n",
    "# ----------------------------\n",
    "print(\"\\nLoading models...\")\n",
    "models_list = [\n",
    "    (\"ResNet34\", load_resnet34(\"resnet34.pth\", num_classes), test_loader_224),\n",
    "    (\"ResNet152\", load_resnet152(\"resnet152.pth\", num_classes), test_loader_224),\n",
    "    (\"DenseNet121\", load_densenet121(\"densenet121.pth\", num_classes), test_loader_224),\n",
    "    (\"EfficientNet-B2\", load_efficientnet_b2(\"efficientnet_b2.pth\", num_classes), test_loader_224),\n",
    "    (\"GoogLeNet\", load_googlenet(\"googlenet.pth\", num_classes), test_loader_224),\n",
    "    (\"InceptionV3\", load_inception_v3(\"inception_v3.pth\", num_classes), test_loader_299),\n",
    "    (\"VGG19\", load_vgg19(\"vgg19.pth\", num_classes), test_loader_224),\n",
    "    (\"SimpleCNN\", load_simplecnn(\"simplecnn.pth\", num_classes), test_loader_gray),  # Use grayscale loader\n",
    "    (\"BAM-ResNet50\", load_bam_resnet50(\"bam_resnet50.pth\", num_classes), test_loader_224),\n",
    "    (\"CBAM-ResNet50\", load_cbam_resnet50(\"cbam_resnet50.pth\", num_classes), test_loader_224),\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Evaluation Functions\n",
    "# ----------------------------\n",
    "def evaluate_single_model(model, dataloader):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def evaluate_ensemble(models_list):\n",
    "    \"\"\"Ensemble with proper handling of different input sizes\"\"\"\n",
    "    # Use 224x224 loader as reference for labels\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    # Get all predictions\n",
    "    all_predictions = []\n",
    "\n",
    "    for name, model, loader in models_list:\n",
    "        model_preds = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, preds = outputs.max(1)\n",
    "                model_preds.append(preds.cpu())\n",
    "        all_predictions.append(torch.cat(model_preds))\n",
    "\n",
    "    # Stack predictions: (num_models, num_samples)\n",
    "    all_predictions = torch.stack(all_predictions)\n",
    "\n",
    "    # Majority voting\n",
    "    final_preds = torch.mode(all_predictions, dim=0).values\n",
    "\n",
    "    # Get true labels\n",
    "    true_labels = []\n",
    "    for _, labels in test_loader_224:\n",
    "        true_labels.append(labels)\n",
    "    true_labels = torch.cat(true_labels)\n",
    "\n",
    "    correct = (final_preds == true_labels).sum().item()\n",
    "    total = len(true_labels)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Run Evaluations\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Individual Model Accuracies:\")\n",
    "print(\"=\"*50)\n",
    "for name, model, loader in models_list:\n",
    "    acc = evaluate_single_model(model, loader)\n",
    "    print(f\"{name:20s}: {acc*100:6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "ensemble_acc = evaluate_ensemble(models_list)\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc*100:.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNeGwg6B00PO",
    "outputId": "4cc96d03-97b3-4c93-ef42-33aba59687f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OPTIMIZED ENSEMBLE - Filtering Poor Performers\n",
      "============================================================\n",
      "ResNet34            :  66.49%\n",
      "ResNet152           :  65.13%\n",
      "DenseNet121         :  68.22%\n",
      "EfficientNet-B2     :  69.91%\n",
      "GoogLeNet           :  54.39%\n",
      "InceptionV3         :  34.69%\n",
      "VGG19               :  66.62%\n",
      "SimpleCNN           :   2.28%\n",
      "BAM-ResNet50        :  65.87%\n",
      "CBAM-ResNet50       :  63.43%\n",
      "\n",
      "============================================================\n",
      "Models above 60% threshold: 7/10\n",
      "============================================================\n",
      "✓ ResNet34            :  66.49%\n",
      "✓ ResNet152           :  65.13%\n",
      "✓ DenseNet121         :  68.22%\n",
      "✓ EfficientNet-B2     :  69.91%\n",
      "✓ VGG19               :  66.62%\n",
      "✓ BAM-ResNet50        :  65.87%\n",
      "✓ CBAM-ResNet50       :  63.43%\n",
      "\n",
      "============================================================\n",
      "Excluded models:\n",
      "============================================================\n",
      "✗ GoogLeNet           :  54.39%\n",
      "✗ InceptionV3         :  34.69%\n",
      "✗ SimpleCNN           :   2.28%\n",
      "\n",
      "============================================================\n",
      "METHOD 1: Majority Voting (Filtered Models)\n",
      "============================================================\n",
      "Ensemble Accuracy: 72.35%\n",
      "\n",
      "============================================================\n",
      "METHOD 2: Weighted Voting (Filtered Models)\n",
      "============================================================\n",
      "\n",
      "Model weights:\n",
      "  ResNet34            : 0.1428 (acc: 66.49%)\n",
      "  ResNet152           : 0.1399 (acc: 65.13%)\n",
      "  DenseNet121         : 0.1465 (acc: 68.22%)\n",
      "  EfficientNet-B2     : 0.1501 (acc: 69.91%)\n",
      "  VGG19               : 0.1431 (acc: 66.62%)\n",
      "  BAM-ResNet50        : 0.1414 (acc: 65.87%)\n",
      "  CBAM-ResNet50       : 0.1362 (acc: 63.43%)\n",
      "\n",
      "Weighted Ensemble Accuracy: 73.07%\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Best Individual Model:        EfficientNet-B2      69.91%\n",
      "All Models Ensemble:          72.19%\n",
      "Filtered Majority Voting:     72.35%\n",
      "Filtered Weighted Voting:     73.07%\n",
      "\n",
      "Improvement over best model:  +3.16%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Filter out models performing below 60% (they add noise)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZED ENSEMBLE - Filtering Poor Performers\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define accuracy threshold\n",
    "ACCURACY_THRESHOLD = 0.60  # 60%\n",
    "\n",
    "# Collect model accuracies\n",
    "model_accuracies = []\n",
    "for name, model, loader in models_list:\n",
    "    acc = evaluate_single_model(model, loader)\n",
    "    model_accuracies.append((name, model, loader, acc))\n",
    "    print(f\"{name:20s}: {acc*100:6.2f}%\")\n",
    "\n",
    "# Filter models above threshold\n",
    "filtered_models = [(name, model, loader, acc) for name, model, loader, acc in model_accuracies\n",
    "                   if acc >= ACCURACY_THRESHOLD]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Models above {ACCURACY_THRESHOLD*100:.0f}% threshold: {len(filtered_models)}/{len(models_list)}\")\n",
    "print(\"=\"*60)\n",
    "for name, _, _, acc in filtered_models:\n",
    "    print(f\"✓ {name:20s}: {acc*100:6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Excluded models:\")\n",
    "print(\"=\"*60)\n",
    "excluded = [(name, acc) for name, _, _, acc in model_accuracies if acc < ACCURACY_THRESHOLD]\n",
    "for name, acc in excluded:\n",
    "    print(f\"✗ {name:20s}: {acc*100:6.2f}%\")\n",
    "\n",
    "# Prepare for ensemble\n",
    "filtered_models_list = [(name, model, loader) for name, model, loader, _ in filtered_models]\n",
    "\n",
    "# Method 1: Simple majority voting with filtered models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 1: Majority Voting (Filtered Models)\")\n",
    "print(\"=\"*60)\n",
    "ensemble_acc_filtered = evaluate_ensemble(filtered_models_list)\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc_filtered*100:.2f}%\")\n",
    "\n",
    "# Method 2: Weighted voting based on individual accuracies\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 2: Weighted Voting (Filtered Models)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def evaluate_weighted_ensemble(models_with_acc):\n",
    "    \"\"\"Weighted ensemble based on model accuracies\"\"\"\n",
    "    # Get predictions and weights from each model\n",
    "    all_logits = []\n",
    "    weights = []\n",
    "\n",
    "    for name, model, loader, acc in models_with_acc:\n",
    "        model_logits = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                model_logits.append(outputs.cpu())\n",
    "        all_logits.append(torch.cat(model_logits))\n",
    "        weights.append(acc)  # Weight by accuracy\n",
    "\n",
    "    # Normalize weights\n",
    "    weights = torch.tensor(weights)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    # Weighted sum of logits\n",
    "    weighted_logits = sum(w * logits for w, logits in zip(weights, all_logits))\n",
    "    final_preds = weighted_logits.argmax(dim=1)\n",
    "\n",
    "    # Get true labels\n",
    "    true_labels = []\n",
    "    for _, labels in test_loader_224:\n",
    "        true_labels.append(labels)\n",
    "    true_labels = torch.cat(true_labels)\n",
    "\n",
    "    correct = (final_preds == true_labels).sum().item()\n",
    "    accuracy = correct / len(true_labels)\n",
    "\n",
    "    # Print weights\n",
    "    print(\"\\nModel weights:\")\n",
    "    for (name, _, _, acc), w in zip(models_with_acc, weights):\n",
    "        print(f\"  {name:20s}: {w.item():.4f} (acc: {acc*100:.2f}%)\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "weighted_acc = evaluate_weighted_ensemble(filtered_models)\n",
    "print(f\"\\nWeighted Ensemble Accuracy: {weighted_acc*100:.2f}%\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Individual Model:        {max(model_accuracies, key=lambda x: x[3])[0]:20s} {max(acc for _, _, _, acc in model_accuracies)*100:.2f}%\")\n",
    "print(f\"All Models Ensemble:          {ensemble_acc*100:.2f}%\")\n",
    "print(f\"Filtered Majority Voting:     {ensemble_acc_filtered*100:.2f}%\")\n",
    "print(f\"Filtered Weighted Voting:     {weighted_acc*100:.2f}%\")\n",
    "print(f\"\\nImprovement over best model:  +{(weighted_acc - max(acc for _, _, _, acc in model_accuracies))*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
